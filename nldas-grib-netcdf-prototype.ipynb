{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is my prototyping platform for the code to extract a timeseries of data from the NLDAS GRB files and store them in NetCDF format.\n",
    "## There should be a .py script with a similar name that runs the finished code on HPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import netCDF4 as nc # http://unidata.github.io/netcdf4-python/\n",
    "import scipy as sp\n",
    "import pygrib as pg\n",
    "import numpy.ma as ma\n",
    "import array as arr \n",
    "import xarray as xr\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the NetCDF forcing data file.\n",
    "grib_dir = '/home/NearingLab/data/nldas/grib/NLDAS2.FORCING/'\n",
    "write_dir = '/home/NearingLab/data/nldas/netcdf-single-cells/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open an example file\n",
    "fname = grib_dir + '1979/001/' + 'NLDAS_FORA0125_H.A19790101.1300.002.grb'\n",
    "#fname = grib_dir + '2019/001/' + 'NLDAS_FORA0125_H.A20190101.0000.002.grb'\n",
    "gbf_temp = pg.open(fname)\n",
    "lats = gbf_temp[1].latitudes\n",
    "lons = gbf_temp[1].longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvars = {0:'airtemp', 1:'spechum', 2:'airpres', 3:'forcingUGRD', 4:'windspd',\n",
    "         5:'LWRadAtm',6:'forcingCONVfrac', 7:'forcingCAPE', 8:'forcingPEVAP', 9:'pptrate', 10:'SWRadAtm'}\n",
    "fvars = {0:'airpres', 1:'airtemp', 2:'pptrate', 3:'spechum', 4:'windspd', 5:'LWRadAtm',6:'SWRadAtm'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 464)\n"
     ]
    }
   ],
   "source": [
    "# Open water mask\n",
    "maskName = 'nldas_info/NLDAS_IGBPpredomveg.asc'\n",
    "km2 = np.genfromtxt(maskName)[:,4]\n",
    "waterMask = np.genfromtxt(maskName)[:,21]\n",
    "for i in range(km2.shape[0]):\n",
    "    if waterMask[i] > km2[i]/2:\n",
    "        waterMask[i] = 'NaN'\n",
    "    elif waterMask[i] <= km2[i]/2:\n",
    "        waterMask[i] = 1\n",
    "waterMask = np.reshape(waterMask,[224,464], order='A') #options are CFA\n",
    "print(waterMask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = int(lats.shape[0]/waterMask.shape[1])\n",
    "ncols= int(lons.shape[0]/waterMask.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will be calculating hours starting from: \n",
      "1979-01-01 13:00:00\n"
     ]
    }
   ],
   "source": [
    "# Set start and end data information for the GRIB/NetCDF forcing data.\n",
    "yearStart  = 1979\n",
    "monthStart = 1 \n",
    "dayStart   = 1 \n",
    "hourStart  = 13\n",
    "startDateTime = dt.datetime(yearStart, monthStart, dayStart, hour = hourStart)\n",
    "print(\"Will be calculating hours starting from: \")\n",
    "print(startDateTime)\n",
    "dayOfYearStart = dt.datetime.date(startDateTime).timetuple().tm_yday\n",
    "yearEnd  = 1979\n",
    "monthEnd = 1\n",
    "dayEnd   = 1 \n",
    "hourEnd  = 23\n",
    "endDateTime = dt.datetime(yearEnd, monthEnd, dayEnd, hour = hourEnd)\n",
    "dayOfYearEnd = dt.datetime.date(endDateTime).timetuple().tm_yday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the directory, but will change each day and year.\n",
    "mainDirectory = '/home/NearingLab/data/nldas/grib/NLDAS2.FORCING/'\n",
    "startDirectory = mainDirectory + str(yearStart)  + \"/\" \\\n",
    "    + str(\"{:03d}\".format(dayOfYearStart))  + \"/\"\n",
    "endDirectory = mainDirectory + str(yearEnd)  + \"/\" \\\n",
    "    + str(\"{:03d}\".format(dayOfYearEnd))  + \"/\"\n",
    "filePrefix = 'NLDAS_FORA0125_H.A'\n",
    "fileSufix = '.002.grb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the data and time to fine the correct file in this name format\n",
    "startFileDateTime = dateForFile(yearStart, monthStart, dayStart, hourStart)\n",
    "endFileDateTime = dateForFile(yearEnd, monthEnd, dayEnd, hourEnd)\n",
    "#Add prefix and sufix to the date to create the whole file name.\n",
    "startFile = getFileName(startFileDateTime, startDirectory, \"A\")\n",
    "endFile = getFileName(endFileDateTime, endDirectory, \"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to get the GRIB time for the first and last files\n",
    "#Start the loop at the first date in the files.\n",
    "year1, month1, day1, hour1 = dateFromGRIB(startFile)\n",
    "t = dt.datetime(year1, month1, day1, hour=hour1)\n",
    "#Then have the loop run until the last file date.\n",
    "year2, month2, day2, hour2 = dateFromGRIB(endFile)\n",
    "endTime = dt.datetime(year2, month2, day2, hour=hour2)\n",
    "# Set timestep to move forward, to run through the files\n",
    "deltime = dt.timedelta(hours=1)\n",
    "# Estimate the number of hours in the record\n",
    "H = endTime - t # (t = startDateTime)\n",
    "# Convert the time difference to hours) \n",
    "H = int(H.total_seconds()/60/60) + 1\n",
    "time = [0 for x in range(H)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of all the times to loop through\n",
    "dates = [startDateTime + deltime*h for h in range(H)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dictionary for each cell, keys named from lat-lon\n",
    "# Will be filled in with data from the grib files\n",
    "G = {}\n",
    "ixy = -1 # Start at -1, so when we add the first value before the mask check, it goes to 0\n",
    "# Now loop across the grid in the X direction\n",
    "for x in range(464):\n",
    "    # Now loop across the grid in the Y direction\n",
    "    for y in range(224):\n",
    "        ixy+=1 # lat/lon from the 1D arrays that correspond to these indices\n",
    "        \n",
    "        if np.ma.is_masked(gbf_temp[11].values[y, x]):\n",
    "            continue\n",
    "        \n",
    "        xy = name_xy(ixy)\n",
    "        G[xy] = setForcingLists(H)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'25.063, -101.938': {'airpres': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'airtemp': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'pptrate': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'spechum': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'windspd': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'SWRadAtm': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'LWRadAtm': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "Current data & time in the main loop is (t): 1979-01-01 13:00:00\n",
      "Hours since the start date: 0\n",
      "----------------------------------------------------\n",
      "Current data & time in the main loop is (t): 1979-01-01 14:00:00\n",
      "Hours since the start date: 1\n",
      "----------------------------------------------------\n",
      "Current data & time in the main loop is (t): 1979-01-01 15:00:00\n",
      "Hours since the start date: 2\n",
      "----------------------------------------------------\n",
      "Current data & time in the main loop is (t): 1979-01-01 16:00:00\n",
      "Hours since the start date: 3\n",
      "----------------------------------------------------\n",
      "Current data & time in the main loop is (t): 1979-01-01 17:00:00\n",
      "Hours since the start date: 4\n",
      "----------------------------------------------------\n",
      "Current data & time in the main loop is (t): 1979-01-01 18:00:00\n",
      "Hours since the start date: 5\n",
      "----------------------------------------------------\n",
      "Current data & time in the main loop is (t): 1979-01-01 19:00:00\n",
      "Hours since the start date: 6\n",
      "----------------------------------------------------\n",
      "Current data & time in the main loop is (t): 1979-01-01 20:00:00\n",
      "Hours since the start date: 7\n",
      "----------------------------------------------------\n",
      "Current data & time in the main loop is (t): 1979-01-01 21:00:00\n",
      "Hours since the start date: 8\n",
      "----------------------------------------------------\n",
      "Current data & time in the main loop is (t): 1979-01-01 22:00:00\n",
      "Hours since the start date: 9\n",
      "----------------------------------------------------\n",
      "Current data & time in the main loop is (t): 1979-01-01 23:00:00\n",
      "Hours since the start date: 10\n"
     ]
    }
   ],
   "source": [
    "# Main loop through the GRIB files by one hour intervals. open, extract, write, save\n",
    "# Main loop through the NetCDF files by one hour intervals. \n",
    "# iH: Index to use for filling forcing data list.\n",
    "for iH, t in enumerate(dates):\n",
    "\n",
    "    hoursSinceStartDate = t - startDateTime\n",
    "    hoursSinceStartDate = int(hoursSinceStartDate.total_seconds()/60/60)\n",
    "    time[iH] = float(hoursSinceStartDate)\n",
    "    print(\"Hours since the start date: {}\".format(hoursSinceStartDate))\n",
    "\n",
    "    # The files have both A and B versions.\n",
    "    AB = \"A\"\n",
    "    # Set the strings for the file name\n",
    "    iYear, iMonth, iDay, iHour = getValuesFromDateTime(t)\n",
    "    # Get the datetime stuff in strings to be used in the NetCDF file call.\n",
    "    dateTime4File = dateForFile(iYear, iMonth, iDay, iHour)\n",
    "    # Need to change the directory to reflect the loop data\n",
    "    directory = changeDirectory(t)\n",
    "    # Put the file name together, this includes the full path\n",
    "    fileName = getFileName(dateTime4File, directory, AB)\n",
    "    # Open the file for this particular data & time.\n",
    "    try:\n",
    "        gbf = pg.open(fileName)\n",
    "    except:\n",
    "        # skip the file\n",
    "        print('File not found:')\n",
    "        print(fileName)\n",
    "        continue\n",
    "    \n",
    "    ixy = -1\n",
    "    # loop across the grid in the X direction\n",
    "    for x in range(464):\n",
    "        # loop across the grid in the Y direction\n",
    "        for y in range(224):            \n",
    "            ixy+=1 # lat/lon from the 1D arrays that correspond to these indices\n",
    "            \n",
    "            if np.ma.is_masked(gbf[11].values[y, x]):\n",
    "                continue\n",
    "            #else:\n",
    "            xy = name_xy(ixy)\n",
    "            g = extractGrib(gbf, x, y)\n",
    "            for iv, v in enumerate(fvars):\n",
    "                G[xy][fvars[v]][iH] = g[fvars[v]]\n",
    "            break\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the forcing data for each cell, individually\n",
    "ixy=-1\n",
    "for x in range(464):\n",
    "    for y in range(224):\n",
    "        ixy+=1 # lat/lon from the 1D arrays that correspond to these indices\n",
    "        if np.ma.is_masked(gbf[11].values[y, x]):\n",
    "            continue\n",
    "            \n",
    "        # Get the lat/lon from the one dimensional arrays that correspond to these indices\n",
    "        \n",
    "        lat=lats[ixy]\n",
    "        lon=lons[ixy]\n",
    "        timestp=3600 #seconds\n",
    "        # Write the NetCDF forcing data file.\n",
    "        fname = \"{}-{}\".format(lats[y], -lons[x])\n",
    "        forcingDataName = write_dir + fname +'.nc'\n",
    "        forcing = nc.Dataset(forcingDataName, 'w', format='NETCDF4_CLASSIC')\n",
    "        forcing.title = \"NLDAS forcing \"+fname\n",
    "        forcing.description = 'NLDAS forcing data for '+fname\n",
    "        forcing = fillForcing(forcing, H, lat, lon, timestp, time, \n",
    "            G[xy]['SWRadAtm'], \n",
    "            G[xy]['LWRadAtm'], \n",
    "            G[xy]['airpres'], \n",
    "            G[xy]['airtemp'], \n",
    "            G[xy]['pptrate'], \n",
    "            G[xy]['spechum'], \n",
    "            G[xy]['windspd'])\n",
    "        os.chmod(forcingDataName, 0o777)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS TO CALL IN THE MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_xy(ixy):\n",
    "    return \"{}, {}\".format(lats[ixy], lons[ixy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for nearest decimal degree in an array of decimal degrees and return the index.\n",
    "# np.argmin returns the indices of minimum value along an axis.\n",
    "# so subtract dd from all values in dd_array, take absolute value and find index of minimum\n",
    "def geo_idx(dd, dd_array):\n",
    "    geo_idx = (np.abs(dd_array - dd)).argmin()\n",
    "    return geo_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search and return the single index in the GRIB file with the lat/long found from geo_idx\n",
    "def geo_idx_1(lat_val, lon_val, lats, lons):\n",
    "    ilat = 0\n",
    "    ilon = 0\n",
    "    print(\"Looking for lat/lon index values\")\n",
    "    #Loop through the one dimensional latitude list,\n",
    "    #Then we'll calculate where we should be in a two dimensional array\n",
    "    for i in range(0, len(lats)):\n",
    "        #At some point we should hit the SINGLE location in the 1D list...\n",
    "        #Where the latitude and longitude values match our grid with our point of interest\n",
    "        if lats[i] == lat_val and lons[i] == lon_val:\n",
    "            #When this happens return those values, because we found our treasure\n",
    "            return [ilat, ilon]\n",
    "        #If for some reason we never find the treasure, let the user know.\n",
    "        #And then end the loop before we get an error for the (i+1) index call\n",
    "        if i == (len(lats)-1):\n",
    "            print(\"ERROR: CAN NOT FIND THE INDEXIES FOR LATITUDE AND LONGITUDE!!!!!!!!\")\n",
    "            return [-99, -99]\n",
    "            break\n",
    "        #If latitudes reach the end of their cycle, then restart\n",
    "        #The latitudes stay constant through the longitudes, then...\n",
    "        #When the longitudes reach the minimum, the latitude moves down one.\n",
    "        if lats[i] != lats[i + 1]:\n",
    "            #Move on, because we've cycled through the longitudes...\n",
    "            # associated with this latitude\n",
    "            ilat = ilat + 1\n",
    "            #The longitudes reset, so the index goes back to zero for the 2D array.\n",
    "            ilon = 0\n",
    "        else:\n",
    "            #The longitudes keep moving while the latitude stays constant.\n",
    "            ilon = ilon + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for lat/lon index values\n",
      "ERROR: CAN NOT FIND THE INDEXIES FOR LATITUDE AND LONGITUDE!!!!!!!!\n",
      "[-99, -99]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'airtemp': 277.63,\n",
       " 'spechum': 0.004764100000000001,\n",
       " 'airpres': 97261.79000000001,\n",
       " 'forcingUGRD': 2.33,\n",
       " 'windspd': 3.77,\n",
       " 'LWRadAtm': 347.03000000000003,\n",
       " 'forcingCONVfrac': 0.0,\n",
       " 'forcingCAPE': 0.0,\n",
       " 'forcingPEVAP': -0.0589,\n",
       " 'pptrate': 0.00022138888888888892,\n",
       " 'SWRadAtm': 9.784}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lat_idx, lon_idx] = geo_idx_1(0, 0, lats, lons)\n",
    "print([lat_idx, lon_idx])\n",
    "extractGrib(gbf_temp, lat_idx, lon_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateForFile(year, month, day, hour):\n",
    "    # Set the strings for the file name\n",
    "    yearStr = str(\"{:02d}\".format(year))\n",
    "    monthStr = str(\"{:02d}\".format(month))\n",
    "    dayStr = str(\"{:02d}\".format(day))\n",
    "    hourStr = str(\"{:02d}\".format(hour))\n",
    "    dateTime = yearStr + monthStr + dayStr + '.' +  hourStr + '00'\n",
    "    return dateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeDirectory(t):\n",
    "    year = dt.datetime.date(t).year\n",
    "    day = dt.datetime.date(t).timetuple().tm_yday\n",
    "    directory = grib_dir + str(year)  + \"/\" + str(\"{:03d}\".format(day))  + \"/\"\n",
    "    return directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileName(dateTime4File, directory, AB):\n",
    "    if AB == \"A\":\n",
    "        filePrefix = 'NLDAS_FORA0125_H.A'\n",
    "    elif AB == \"B\":\n",
    "        filePrefix = 'NLDAS_FORB0125_H.A'\n",
    "    fileSufix = '.002.grb'\n",
    "    fileName = directory + filePrefix + dateTime4File + fileSufix\n",
    "    return fileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateFromNetCDF(fileName):\n",
    "    file_in = nc.Dataset(fileName,\"r\",format=\"NETCDF4\")\n",
    "    t_unit = file_in.variables[\"time\"].units # get unit  \"days since 1950-01-01T00:00:00Z\"\n",
    "    print(\"NetCDF file units for time are:\")\n",
    "    print(t_unit)\n",
    "    year = int(t_unit[12:15+1])\n",
    "    month = int(t_unit[17:18+1])\n",
    "    day = int(t_unit[20:21+1])\n",
    "    hour = int(t_unit[23:24+1])\n",
    "    return t_unit, year, month, day, hour;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateFromGRIB(fileName):\n",
    "    file_in = pg.open(fileName)\n",
    "    gribData = file_in.select()[0]\n",
    "    year = int(gribData.year)\n",
    "    month = int(gribData.month)\n",
    "    day = int(gribData.day)\n",
    "    hour = int(gribData.hour)\n",
    "\n",
    "    return year, month, day, hour;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValuesFromDateTime(t):\n",
    "    y = dt.datetime.date(t).year\n",
    "    m = dt.datetime.date(t).month\n",
    "    d = dt.datetime.date(t).day\n",
    "    h = dt.datetime.time(t).hour\n",
    "    return y, m, d, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillForcing(forcing, H, lat, lon, timestp, time, \\\n",
    "                SWRadAtm, LWRadAtm, airpres, airtemp, pptrate, spechum, windspd):\n",
    "    forcing.createDimension('hru', 1)\n",
    "    forcing.createDimension('time', H)\n",
    "    ### createVareables in new data set\n",
    "    forcing.createVariable('latitude', np.float32, ('hru',))\n",
    "    forcing.variables['latitude'].units = 'decimal degree'\n",
    "    forcing.variables['latitude'].long_name = 'Latitude location of HRU, North-South decimal degrees'\n",
    "    forcing.createVariable('longitude', np.float32, ('hru',))\n",
    "    forcing.variables['longitude'].units = 'decimal degree'\n",
    "    forcing.variables['longitude'].long_name = 'Longitude location of HRU, East-West decimal degrees'\n",
    "    forcing.createVariable('data_step', np.int32)\n",
    "    forcing.variables['data_step'].units = 'seconds'\n",
    "    forcing.variables['data_step'].long_name = 'data step length in seconds'\n",
    "    forcing.createVariable('time', np.float64, ('time',))\n",
    "    forcing.variables['time'].units = 'hours since 1979-01-01 00:00:00'\n",
    "    forcing.variables['time'].long_name = 'time of forcing data'\n",
    "    forcing.createVariable('LWRadAtm', np.float32, ('time', 'hru'))\n",
    "    forcing.variables['LWRadAtm'].units = 'W m-2'\n",
    "    forcing.variables['LWRadAtm'].long_name = 'downward longwave radiation at the upper boundary'\n",
    "    forcing.variables['LWRadAtm'].v_type     = 'scalarv'\n",
    "    forcing.createVariable('SWRadAtm', np.float32, ('time', 'hru'))\n",
    "    forcing.variables['SWRadAtm'].units = 'W m-2'\n",
    "    forcing.variables['SWRadAtm'].long_name = 'downward shortwave radiation at the upper boundary'\n",
    "    forcing.variables['SWRadAtm'].v_type     = 'scalarv'\n",
    "    forcing.createVariable('airpres', np.float32, ('time', 'hru'))\n",
    "    forcing.variables['airpres'].units = 'Pa'\n",
    "    forcing.variables['airpres'].long_name = 'air pressure at the measurement height'\n",
    "    forcing.variables['airpres'].v_type     = 'scalarv'\n",
    "    forcing.createVariable('airtemp', np.float32, ('time', 'hru'))\n",
    "    forcing.variables['airtemp'].units = 'K'\n",
    "    forcing.variables['airtemp'].long_name = 'air temperature at the measurement height'\n",
    "    forcing.variables['airtemp'].v_type     = 'scalarv'\n",
    "    forcing.createVariable('pptrate', np.float32, ('time', 'hru'))\n",
    "    forcing.variables['pptrate'].units = 'kg m-2 s-1'\n",
    "    forcing.variables['pptrate'].long_name = 'Precipitation rate'\n",
    "    forcing.variables['pptrate'].v_type     = 'scalarv'\n",
    "    forcing.createVariable('spechum', np.float32, ('time', 'hru'))\n",
    "    forcing.variables['spechum'].units = 'g g-1'\n",
    "    forcing.variables['spechum'].long_name = 'specific humidity at the measurement height'\n",
    "    forcing.variables['spechum'].v_type     = 'scalarv'\n",
    "    forcing.createVariable('windspd', np.float32, ('time', 'hru'))\n",
    "    forcing.variables['windspd'].units = 'm s-1'\n",
    "    forcing.variables['windspd'].long_name = 'wind speed at the measurement height'\n",
    "    forcing.variables['windspd'].v_type     = 'scalarv'\n",
    "    # Fill new data set with diplicate values\n",
    "    forcing.variables['latitude'][:]       = lat\n",
    "    forcing.variables['longitude'][:]      = lon\n",
    "    forcing.variables['data_step'][:]      = timestp\n",
    "    forcing.variables['time'][:]      = np.transpose(time)\n",
    "    forcing.variables['SWRadAtm'][:]  = np.transpose(SWRadAtm)\n",
    "    forcing.variables['LWRadAtm'][:]  = np.transpose(LWRadAtm)\n",
    "    forcing.variables['airpres'][:]   = np.transpose(airpres)\n",
    "    forcing.variables['airtemp'][:]   = np.transpose(airtemp)\n",
    "    forcing.variables['pptrate'][:]   = np.transpose(pptrate)\n",
    "    forcing.variables['spechum'][:]   = np.transpose(spechum)\n",
    "    forcing.variables['windspd'][:]   = np.transpose(windspd)\n",
    "\n",
    "    return forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setForcingLists(H):\n",
    "    # Set the vectors (Python List) with these hours for the forcing data\n",
    "    # Air pressure at the measurement height\n",
    "    airpres = [0 for x in range(H)] #[Pa]\n",
    "    # Air temperature at the measurement height\n",
    "    airtemp = [0 for x in range(H)]#[K]\n",
    "    # Downward longwave radiation at the upper boundary\n",
    "    LWRadAtm = [0 for x in range(H)] #[W m-2] \n",
    "    # Precipitation rate\n",
    "    pptrate = [0 for x in range(H)] #[kg m-2 s-1]\n",
    "    # Specific humifity at the measurement height\n",
    "    spechum = [0 for x in range(H)] #[g g-1]\n",
    "    # Downward shortwave radiation at the upper boundary\n",
    "    SWRadAtm = [0 for x in range(H)] #[W m-2]\n",
    "    # Observation time\n",
    "    time = [0 for x in range(H)] #[days since 1979-01-01 00:00:00]\n",
    "    #wind speed at the measurement height\n",
    "    windspd = [0 for x in range(H)] #[m s-1]\n",
    "\n",
    "    F = {'airpres':airpres, 'airtemp':airtemp, 'pptrate':pptrate, 'spechum':spechum, 'windspd':windspd,\n",
    "        'SWRadAtm':SWRadAtm, 'LWRadAtm':LWRadAtm}\n",
    "    \n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractGrib(g, lon_idx, lat_idx, verbose=False):\n",
    "\n",
    "    # Return value of \"MASKED\" if masked\n",
    "    if np.ma.is_masked(g[11].values[lat_idx, lon_idx]):\n",
    "        return {'airtemp':-9999, 'spechum':-9999, 'airpres':-9999, 'forcingUGRD':-9999, \n",
    "       'windspd':-9999, 'LWRadAtm':-9999, 'forcingCONVfrac':-9999, \n",
    "       'forcingCAPE':-9999,'forcingPEVAP':-9999, 'pptrate':-9999, 'SWRadAtm':-9999}\n",
    "    \n",
    "    # 1:11:11 TMP, 2-m above ground Temperature [K]\n",
    "    airtemp = g[1].values[lat_idx, lon_idx] \n",
    "    # 2:51:51 SPFH, 2-m above ground Specific humidity [kg/kg]\n",
    "    spechum = g[2].values[lat_idx, lon_idx] \n",
    "    # 3:1:1 PRES, Surface pressure [Pa]\n",
    "    airpres = g[3].values[lat_idx, lon_idx] \n",
    "    # 4:33:33 UGRD, 10-m above ground Zonal wind speed [m/s]\n",
    "    forcingUGRD = g[4].values[lat_idx, lon_idx]\n",
    "    # 5:34:34 VGRD, 10-m above ground Meridonal wind speed [m/s]\n",
    "    windspd = g[5].values[lat_idx, lon_idx] \n",
    "    # 6:205:205 DLWRF,  Longwave radiation flux downwards [W/m^2]\n",
    "    LWRadAtm = g[6].values[lat_idx, lon_idx]\n",
    "    # 7:153:153 CONVfrac, Frac of total precip convective\n",
    "    forcingCONVfrac = g[7].values[lat_idx, lon_idx] \n",
    "    # 8:157:157 CAPE, 180-mb above ground Convective Available Potential Energy\n",
    "    forcingCAPE = g[8].values[lat_idx, lon_idx] \n",
    "    \n",
    "    # PEVAP, Potential evaporation hourly total   MAYBE: Adiabatic tendency of temperature?\n",
    "    forcingPEVAP = g[9].values[lat_idx, lon_idx]\n",
    "    \n",
    "    # 10:61:61 APCP, Precipitation hourly total [kg/m^2/hr]\n",
    "    pptrate = g[10].values[lat_idx, lon_idx] / 60 / 60\n",
    "    \n",
    "    # 11:204:204 DSWRF, Shortwave radiation flux downwards (surface) [W/m^2]\n",
    "    SWRadAtm = g[11].values[lat_idx, lon_idx]\n",
    "            \n",
    "    G={'airtemp':airtemp, 'spechum':spechum, 'airpres':airpres, 'forcingUGRD':forcingUGRD, \n",
    "       'windspd':windspd, 'LWRadAtm':LWRadAtm, 'forcingCONVfrac':forcingCONVfrac, \n",
    "       'forcingCAPE':forcingCAPE,'forcingPEVAP':forcingPEVAP, 'pptrate':pptrate, 'SWRadAtm':SWRadAtm}\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"TMP, 2-m above ground Temperature [K]: {}\".format(airtemp))\n",
    "        print(\"SPFH, 2-m above ground Specific humidity [kg/kg]: {}\".format(spechum))\n",
    "        print(\"PRES, Surface pressure [Pa]: {}\".format(airpres))\n",
    "        print(\"UGRD, 10-m above ground Zonal wind speed [m/s]: {}\".format(forcingUGRD))\n",
    "        print(\"VGRD, 10-m above ground Meridonal wind speed [m/s]: {}\".format(windspd))\n",
    "        print(\"DLWRF,  Longwave radiation flux downwards (surface) [W/m^2]: {}\".format(LWRadAtm))\n",
    "        print(\"CONVfrac, Fraction of total precipitation that is convective: {}\".format(forcingCONVfrac))\n",
    "        print(\"CAPE, 180-mb above ground Convective Available Potential Energy: {}\".format(forcingCAPE))\n",
    "        print(\"PEVAP, Potential evaporation hourly total: {}\".format(forcingPEVAP))\n",
    "        print(\"APCP, Precipitation hourly total [kg/m^2/hr]: {}\".format(pptrate))\n",
    "        print(\"DSWRF, Shortwave radiation flux downwards (surface) [W/m^2]: {}\".format(SWRadAtm))\n",
    "        \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75958\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for x in range(464):\n",
    "    for y in range(224):\n",
    "        if waterMask[y,x]==1:\n",
    "            count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 464)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lats.reshape(224,464).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 464)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lons.reshape(224,464).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMP, 2-m above ground Temperature [K]: 266.75\n",
      "SPFH, 2-m above ground Specific humidity [kg/kg]: 0.0022709000000000006\n",
      "PRES, Surface pressure [Pa]: 96939.23\n",
      "UGRD, 10-m above ground Zonal wind speed [m/s]: -1.6400000000000001\n",
      "VGRD, 10-m above ground Meridonal wind speed [m/s]: -2.24\n",
      "DLWRF,  Longwave radiation flux downwards (surface) [W/m^2]: 279.53000000000003\n",
      "CONVfrac, Fraction of total precipitation that is convective: 0.0\n",
      "CAPE, 180-mb above ground Convective Available Potential Energy: 0.0\n",
      "PEVAP, Potential evaporation hourly total: 0.0178\n",
      "APCP, Precipitation hourly total [kg/m^2/hr]: 7.183333333333332e-05\n",
      "DSWRF, Shortwave radiation flux downwards (surface) [W/m^2]: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'airtemp': 266.75,\n",
       " 'spechum': 0.0022709000000000006,\n",
       " 'airpres': 96939.23,\n",
       " 'forcingUGRD': -1.6400000000000001,\n",
       " 'windspd': -2.24,\n",
       " 'LWRadAtm': 279.53000000000003,\n",
       " 'forcingCONVfrac': 0.0,\n",
       " 'forcingCAPE': 0.0,\n",
       " 'forcingPEVAP': 0.0178,\n",
       " 'pptrate': 7.183333333333332e-05,\n",
       " 'SWRadAtm': 0.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractGrib(gbf_temp, 400, 200, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airtemp': -9999,\n",
       " 'spechum': -9999,\n",
       " 'airpres': -9999,\n",
       " 'forcingUGRD': -9999,\n",
       " 'windspd': -9999,\n",
       " 'LWRadAtm': -9999,\n",
       " 'forcingCONVfrac': -9999,\n",
       " 'forcingCAPE': -9999,\n",
       " 'forcingPEVAP': -9999,\n",
       " 'pptrate': -9999,\n",
       " 'SWRadAtm': -9999}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractGrib(gbf_temp, 0, 0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021000000000000003"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbf[9].values[100,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-99"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lon_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
