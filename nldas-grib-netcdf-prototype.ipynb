{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is my prototyping platform for the code to extract a timeseries of data from the NLDAS GRB files and store them in NetCDF format.\n",
    "## There should be a .py script with a similar name that runs the finished code on HPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import netCDF4 as nc # http://unidata.github.io/netcdf4-python/\n",
    "import pygrib as pg\n",
    "import sys\n",
    "import os\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import pickle as pkl\n",
    "import nldas_pygrib_tools as npt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the NetCDF forcing data file.\n",
    "grib_dir = '/home/NearingLab/data/nldas/grib/NLDAS2.FORCING/'\n",
    "write_dir = '/home/NearingLab/data/nldas/netcdf-single-cells/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open an example file\n",
    "fname = grib_dir + '1979/001/' + 'NLDAS_FORA0125_H.A19790101.1300.002.grb'\n",
    "#fname = grib_dir + '2019/001/' + 'NLDAS_FORA0125_H.A20190101.0000.002.grb'\n",
    "gbf_temp = pg.open(fname)\n",
    "lats = gbf_temp[1].latitudes\n",
    "lons = gbf_temp[1].longitudes\n",
    "nrows = gbf_temp[11].values.shape[0]\n",
    "ncols = gbf_temp[11].values.shape[1]\n",
    "N = nrows*ncols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvars = {0:'airtemp', 1:'spechum', 2:'airpres', 3:'forcingUGRD', 4:'windspd',\n",
    "         5:'LWRadAtm',6:'forcingCONVfrac', 7:'forcingCAPE', 8:'forcingPEVAP', 9:'pptrate', 10:'SWRadAtm'}\n",
    "fvars = {0:'airpres', 1:'airtemp', 2:'pptrate', 3:'spechum', 4:'windspd', 5:'LWRadAtm',6:'SWRadAtm'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will be calculating hours starting from: \n",
      "1979-01-01 13:00:00\n"
     ]
    }
   ],
   "source": [
    "# Set start and end data information for the GRIB/NetCDF forcing data.\n",
    "yearStart  = 1979\n",
    "monthStart = 1 \n",
    "dayStart   = 1 \n",
    "hourStart  = 13\n",
    "startDateTime = dt.datetime(yearStart, monthStart, dayStart, hour = hourStart)\n",
    "print(\"Will be calculating hours starting from: \")\n",
    "print(startDateTime)\n",
    "dayOfYearStart = dt.datetime.date(startDateTime).timetuple().tm_yday\n",
    "yearEnd  = 1979\n",
    "monthEnd = 1\n",
    "dayEnd   = 1 \n",
    "hourEnd  = 23\n",
    "endDateTime = dt.datetime(yearEnd, monthEnd, dayEnd, hour = hourEnd)\n",
    "dayOfYearEnd = dt.datetime.date(endDateTime).timetuple().tm_yday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the directory, but will change each day and year.\n",
    "mainDirectory = '/home/NearingLab/data/nldas/grib/NLDAS2.FORCING/'\n",
    "startDirectory = mainDirectory + str(yearStart)  + \"/\" \\\n",
    "    + str(\"{:03d}\".format(dayOfYearStart))  + \"/\"\n",
    "endDirectory = mainDirectory + str(yearEnd)  + \"/\" \\\n",
    "    + str(\"{:03d}\".format(dayOfYearEnd))  + \"/\"\n",
    "filePrefix = 'NLDAS_FORA0125_H.A'\n",
    "fileSufix = '.002.grb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the data and time to fine the correct file in this name format\n",
    "startFileDateTime = npt.dateForFile(yearStart, monthStart, dayStart, hourStart)\n",
    "endFileDateTime = npt.dateForFile(yearEnd, monthEnd, dayEnd, hourEnd)\n",
    "#Add prefix and sufix to the date to create the whole file name.\n",
    "startFile = npt.getFileName(startFileDateTime, startDirectory, \"A\")\n",
    "endFile = npt.getFileName(endFileDateTime, endDirectory, \"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to get the GRIB time for the first and last files\n",
    "#Start the loop at the first date in the files.\n",
    "year1, month1, day1, hour1 = npt.dateFromGRIB(startFile)\n",
    "t = dt.datetime(year1, month1, day1, hour=hour1)\n",
    "#Then have the loop run until the last file date.\n",
    "year2, month2, day2, hour2 = npt.dateFromGRIB(endFile)\n",
    "endTime = dt.datetime(year2, month2, day2, hour=hour2)\n",
    "# Set timestep to move forward, to run through the files\n",
    "deltime = dt.timedelta(hours=1)\n",
    "# Estimate the number of hours in the record\n",
    "H = endTime - t # (t = startDateTime)\n",
    "# Convert the time difference to hours) \n",
    "H = int(H.total_seconds()/60/60) + 1\n",
    "time_series = [0 for x in range(H)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a list of all the times to loop through\n",
    "dates = [startDateTime + deltime*h for h in range(H)]\n",
    "len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6729aa984cdc4b3e838ca795e8b433fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=464.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-40714f198216>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mixy\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;31m# lat/lon from the 1D arrays that correspond to these indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_masked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbf_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Skip masked cells, takes .0044 seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mxy_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mixy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpygrib.pyx\u001b[0m in \u001b[0;36mpygrib.gribmessage.__getattr__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpygrib.pyx\u001b[0m in \u001b[0;36mpygrib.gribmessage.__getitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpygrib.pyx\u001b[0m in \u001b[0;36mpygrib.gribmessage._reshape_mask\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# find all the masked cells before the main loop, and avoid them\n",
    "ixy = -1 # Start at -1, so when we add the first value before the mask check, it goes to 0\n",
    "xy_list = []\n",
    "for x in tqdm(range(464)):\n",
    "    for y in range(224):            \n",
    "        ixy+=1 # lat/lon from the 1D arrays that correspond to these indices\n",
    "        if np.ma.is_masked(gbf_temp[11].values[y, x]): # Skip masked cells, takes .0044 seconds\n",
    "            continue\n",
    "        xy_list.append(ixy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840f24597ca34f359d873210a6642e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up a dictionary for each cell, keys named from lat-lon\n",
    "# Will be filled in with data from the grib files\n",
    "G = {}\n",
    "for ixy in tqdm(xyloop):\n",
    "    xy = npt.name_xy(ixy, lats, lons)\n",
    "    G[xy] = npt.setForcingLists(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e978f36088e544c3a9a3da408d000ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 2.3603439331054688e-05\n",
      "t2 0.00018644332885742188\n",
      "t3 0.06183290481567383\n",
      "t4 6.723403930664062e-05\n"
     ]
    }
   ],
   "source": [
    "# Main loop through the GRIB files by one hour intervals. open, extract, write, save\n",
    "# Main loop through the NetCDF files by one hour intervals. \n",
    "# iH: Index to use for filling forcing data list.\n",
    "for iH, t in enumerate(tqdm(dates)):\n",
    "\n",
    "    hoursSinceStartDate = t - startDateTime\n",
    "    hoursSinceStartDate = int(hoursSinceStartDate.total_seconds()/60/60)\n",
    "    time_series[iH] = float(hoursSinceStartDate)\n",
    "\n",
    "    # The files have both A and B versions.\n",
    "    AB = \"A\"\n",
    "    # Set the strings for the file name\n",
    "    iYear, iMonth, iDay, iHour = npt.getValuesFromDateTime(t)\n",
    "    # Get the datetime stuff in strings to be used in the NetCDF file call.\n",
    "    dateTime4File = npt.dateForFile(iYear, iMonth, iDay, iHour)\n",
    "    # Need to change the directory to reflect the loop data\n",
    "    directory = npt.changeDirectory(t, grib_dir)\n",
    "    # Put the file name together, this includes the full path\n",
    "    fileName = npt.getFileName(dateTime4File, directory, AB)\n",
    "    # Open the file for this particular data & time.\n",
    "    try:\n",
    "        gbf = pg.open(fileName)\n",
    "    except:\n",
    "        # skip the file\n",
    "        print('File not found: \\n',fileName)\n",
    "        continue\n",
    "    \n",
    "#####################################################################\n",
    "#####################################################################\n",
    "#####   THIS IS A MAJOR CHANGE, AND IS NOT WORKING YET  #############\n",
    "    g = extractGrib(gbf, ixy, nrows, ncols)\n",
    "#####   NEED TO COLLECT DATA IN VECTOR, THEN ASSIGN TO THE CELL SOMEHOW\n",
    "\n",
    "\n",
    "    # Looping takes too long. Need to get all values in vector\n",
    "    # through x,y 1D indices.\n",
    "    for ixy in xyloop:\n",
    "\n",
    "        xy = npt.name_xy(ixy, lats, lons)\n",
    "        \n",
    "        # Need to get the two dimensional x,y values from the 1D xy\n",
    "        x, y = np.unravel_index(ixy, (ncols,nrows))\n",
    "                \n",
    "        # Fill in the main Grib dictionary.\n",
    "        for iv, v in enumerate(fvars):\n",
    "            G[xy][fvars[v]][iH] = g[fvars[v]].reshape\n",
    "\n",
    "    # Save the whole data periodically.\n",
    "    save_G_name = write_dir+'grib_export.pkl'\n",
    "    with open(save_G_name,'wb') as f:\n",
    "        pkl.dump(G, f)\n",
    "    os.chmod(save_G_name, 0o777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = extractGrib(gbf, ixy, nrows, ncols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g['airtemp'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractGrib(g, ixy, nrows, ncols, verbose=False):\n",
    "    # 1:11:11 TMP, 2-m above ground Temperature [K]\n",
    "    airtemp = np.array(g[1].values.reshape(nrows,ncols)[ixy])\n",
    "\n",
    "    # 2:51:51 SPFH, 2-m above ground Specific humidity [kg/kg]\n",
    "    spechum = np.array(g[2].values.reshape(nrows,ncols)[ixy])\n",
    "    # 3:1:1 PRES, Surface pressure [Pa]\n",
    "    airpres = np.array(g[3].values.reshape(nrows,ncols)[ixy])\n",
    "    # 4:33:33 UGRD, 10-m above ground Zonal wind speed [m/s]\n",
    "    forcingUGRD = np.array(g[4].values.reshape(nrows,ncols)[ixy])\n",
    "    # 5:34:34 VGRD, 10-m above ground Meridonal wind speed [m/s]\n",
    "    windspd = np.array(g[5].values.reshape(nrows,ncols)[ixy])\n",
    "    # 6:205:205 DLWRF,  Longwave radiation flux downwards [W/m^2]\n",
    "    LWRadAtm = np.array(g[6].values.reshape(nrows,ncols)[ixy])\n",
    "    # 7:153:153 CONVfrac, Frac of total precip convective\n",
    "    forcingCONVfrac = np.array(g[7].values.reshape(nrows,ncols)[ixy])\n",
    "    # 8:157:157 CAPE, 180-mb above ground Convective Available Potential Energy\n",
    "    forcingCAPE = np.array(g[8].values.reshape(nrows,ncols)[ixy])\n",
    "        \n",
    "    # PEVAP, Potential evaporation hourly total   MAYBE: Adiabatic tendency of temperature?\n",
    "    forcingPEVAP = np.array(g[9].values.reshape(nrows,ncols)[ixy])\n",
    "        \n",
    "    # 10:61:61 APCP, Precipitation hourly total [kg/m^2/hr]\n",
    "    pptrate = np.array(g[10].values.reshape(nrows,ncols)[ixy]) / 60 / 60\n",
    "        \n",
    "    # 11:204:204 DSWRF, Shortwave radiation flux downwards (surface) [W/m^2]\n",
    "    SWRadAtm = np.array(g[11].values.reshape(nrows,ncols)[ixy])\n",
    "                 \n",
    "    G={'airtemp':airtemp, 'spechum':spechum, 'airpres':airpres, 'forcingUGRD':forcingUGRD, \n",
    "       'windspd':windspd, 'LWRadAtm':LWRadAtm, 'forcingCONVfrac':forcingCONVfrac, \n",
    "       'forcingCAPE':forcingCAPE,'forcingPEVAP':forcingPEVAP, 'pptrate':pptrate, 'SWRadAtm':SWRadAtm}\n",
    "           \n",
    "    if verbose:\n",
    "        print(\"TMP, 2-m above ground Temperature [K]: {}\".format(airtemp))\n",
    "        print(\"SPFH, 2-m above ground Specific humidity [kg/kg]: {}\".format(spechum))\n",
    "        print(\"PRES, Surface pressure [Pa]: {}\".format(airpres))\n",
    "        print(\"UGRD, 10-m above ground Zonal wind speed [m/s]: {}\".format(forcingUGRD))\n",
    "        print(\"VGRD, 10-m above ground Meridonal wind speed [m/s]: {}\".format(windspd))\n",
    "        print(\"DLWRF,  Longwave radiation flux downwards (surface) [W/m^2]: {}\".format(LWRadAtm))\n",
    "        print(\"CONVfrac, Fraction of total precipitation that is convective: {}\".format(forcingCONVfrac))\n",
    "        print(\"CAPE, 180-mb above ground Convective Available Potential Energy: {}\".format(forcingCAPE))\n",
    "        print(\"PEVAP, Potential evaporation hourly total: {}\".format(forcingPEVAP))\n",
    "        print(\"APCP, Precipitation hourly total [kg/m^2/hr]: {}\".format(pptrate))\n",
    "        print(\"DSWRF, Shortwave radiation flux downwards (surface) [W/m^2]: {}\".format(SWRadAtm))\n",
    "            \n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the forcing data for each cell, individually\n",
    "for ixy in tqdm(xyloop):\n",
    "    x, y = np.unravel_index(ixy, (ncols,nrows))\n",
    "    lat=lats[ixy]\n",
    "    lon=lons[ixy]\n",
    "    timestp=3600 #seconds\n",
    "    # Write the NetCDF forcing data file.\n",
    "    fname = \"{}-{}\".format(lats[y], -lons[x])\n",
    "    forcingDataName = write_dir + fname +'.nc'\n",
    "    forcing = nc.Dataset(forcingDataName, 'w', format='NETCDF4_CLASSIC')\n",
    "    forcing.title = \"NLDAS forcing \"+fname\n",
    "    forcing.description = 'NLDAS forcing data for '+fname\n",
    "    forcing = fillForcing(forcing, H, lat, lon, timestp, time_series, \n",
    "        G[xy]['SWRadAtm'], \n",
    "        G[xy]['LWRadAtm'], \n",
    "        G[xy]['airpres'], \n",
    "        G[xy]['airtemp'], \n",
    "        G[xy]['pptrate'], \n",
    "        G[xy]['spechum'], \n",
    "        G[xy]['windspd'])\n",
    "    os.chmod(forcingDataName, 0o777)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
